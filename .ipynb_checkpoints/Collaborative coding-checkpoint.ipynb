{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ad20ef",
   "metadata": {},
   "source": [
    "Collaborative coding using GitHub\n",
    "===========\n",
    "\n",
    "Alexandre Perera Luna, Mónica Rojas Martínez\n",
    "\n",
    "December 15th 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9faf46",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The objective of this assignment is to construct a project through collaborative coding, showcasing an Exploratory Data Analysis (EDA) and a classification. To facilitate your understanding of GitHub, we will utilize code snippets from previous exercises, allowing you to focus on the process without concerns about the final outcome. The current notebook will serve as the main function in the project, and each participant is required to develop additional components and integrate their contributions into the main branch.\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "In order to work with functions created in other jupyter notebooks you need to install the package `nbimporter` using a shell and the following command:\n",
    "\n",
    "<font color='grey'>pip install nbimporter</font> \n",
    "\n",
    "`nbimporter` allows you to import jupyter notebooks as modules. Once intalled and imported, you can use a command like the following to import a function called *fibonacci* that is stored on a notebook *fibbo_func* in the same path as the present notebook:\n",
    "\n",
    "<font color='green'>from</font> fibbo_func <font color='green'>import</font> fibbonaci  <font color='green'>as</font> fibbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccb4045",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbimporter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Modify this cell by importing all the necessary modules you need to solve the assigmnent. Observe that we are importing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m## the library nbimporter. You will need it for calling fuctions created in other notebooks. \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnbimporter\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nbimporter'"
     ]
    }
   ],
   "source": [
    "## Modify this cell by importing all the necessary modules you need to solve the assigmnent. Observe that we are importing\n",
    "## the library nbimporter. You will need it for calling fuctions created in other notebooks. \n",
    "import nbimporter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a064a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fibbo_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Here is an example of invoking the Fibonacci function, whisch should be located in the same directory as the main:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfibbo_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fibbonaci \u001b[38;5;28;01mas\u001b[39;00m fibbo\n\u001b[0;32m      3\u001b[0m fibbo(\u001b[38;5;241m24\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fibbo_func'"
     ]
    }
   ],
   "source": [
    "# Here is an example of invoking the Fibonacci function, whisch should be located in the same directory as the main:\n",
    "from fibbo_func import fibbonaci as fibbo\n",
    "fibbo(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb6f6b0",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "As an illustration of Git workflow, you will analyze the *Parkinson's* dataset, which has been previously examined in past assignments. Each team member has specific responsibilities that may be crucial for the progress of others. Make sure all of you organize your tasks accordingly. We've structured the analysis into modules to assist you in tracking your tasks, but feel free to deviate from it if you prefer.   \n",
    "Please use Markdown cells for describing your workflow and expalining the findings of your work. \n",
    "Remember you need both, to modify this notebook and, to create additional functions outside. Your work will only be available for others when you modify and merge your changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8690e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We will start by loading the parkinson dataset. The rest is up to you!\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparkinsons.data\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      3\u001b[0m                  dtype \u001b[38;5;241m=\u001b[39m { \u001b[38;5;66;03m# indicate categorical variables\u001b[39;00m\n\u001b[0;32m      4\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# We will start by loading the parkinson dataset. The rest is up to you!\n",
    "df = pd.read_csv('parkinsons.data', \n",
    "                 dtype = { # indicate categorical variables\n",
    "                     'status': 'category'})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c433fda",
   "metadata": {},
   "source": [
    "### 1. Cleaning and tidying the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34465cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_names = {'MDVP:Fo(Hz)':'avFF',\n",
    "              'MDVP:Fhi(Hz)':'maxFF', \n",
    "              'MDVP:Flo(Hz)':'minFF',\n",
    "              'MDVP:Jitter(%)': 'percJitter',\n",
    "              'MDVP:Jitter(Abs)':'absJitter' ,\n",
    "              'MDVP:RAP': 'rap',\n",
    "              'MDVP:PPQ': 'ppq',\n",
    "              'Jitter:DDP': 'ddp',\n",
    "              'MDVP:Shimmer' : 'lShimer',\n",
    "              'MDVP:Shimmer(dB)': 'dbShimer',\n",
    "              'Shimmer:APQ3':'apq3',\n",
    "              'Shimmer:APQ5': 'apq5',\n",
    "              'MDVP:APQ':'apq',\n",
    "              'Shimmer:DDA':'dda'}\n",
    "# Rename variables\n",
    "from renamevars import renamevars\n",
    "df = renamevars(df, dict_names)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617353cb",
   "metadata": {},
   "source": [
    "### 2. Basic EDA based on plots and descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from scat_plt_function import scat_plt\n",
    "\n",
    "# Fundamental frequency variables\n",
    "fundamental_frequency_vars = df[['avFF', 'maxFF', 'minFF', 'status']]\n",
    "\n",
    "# Generating the scatter plot using the scat_plt function\n",
    "scat_plt(fundamental_frequency_vars['avFF'], fundamental_frequency_vars['maxFF'], fundamental_frequency_vars['status'])\n",
    "scat_plt(fundamental_frequency_vars['avFF'], fundamental_frequency_vars['minFF'], fundamental_frequency_vars['status'])\n",
    "scat_plt(fundamental_frequency_vars['minFF'], fundamental_frequency_vars['maxFF'], fundamental_frequency_vars['status'])\n",
    "\n",
    "# Eliminates the columns that are not important for the fundamental frequency\n",
    "cleaned_df_fundamental = df.drop(columns = ['avFF', 'maxFF','percJitter','absJitter','rap','ppq','ddp','lShimer','dbShimer','apq3', 'apq5', 'apq', 'dda'])\n",
    "\n",
    "#########################################################################################################################################################################\n",
    "\n",
    "# Jitter scatter plots\n",
    "jitter_vars = df[['absJitter', 'rap', 'ppq', 'ddp', 'status']]\n",
    "\n",
    "# Generating the scatter plot using the scat_plt function\n",
    "scat_plt(jitter_vars['absJitter'], jitter_vars['rap'], jitter_vars['status'])\n",
    "scat_plt(jitter_vars['absJitter'], jitter_vars['ppq'], jitter_vars['status'])\n",
    "scat_plt(jitter_vars['absJitter'], jitter_vars['ddp'], jitter_vars['status'])\n",
    "scat_plt(jitter_vars['rap'], jitter_vars['ppq'], jitter_vars['status'])\n",
    "scat_plt(jitter_vars['rap'], jitter_vars['ddp'], jitter_vars['status'])\n",
    "scat_plt(jitter_vars['ppq'], jitter_vars['ddp'], jitter_vars['status'])\n",
    "\n",
    "# Eliminates the columns that are not important for the Jitter\n",
    "cleaned_df_jitter = df.drop(columns = ['maxFF','minFF','avFF','percJitter','absJitter','lShimer','dbShimer','apq3','apq5','apq','dda'])\n",
    "\n",
    "#######################################################################################################################################################\n",
    "\n",
    "# Shimer scatter plots\n",
    "shimer_vars = df[['lShimer', 'dbShimer', 'apq3', 'apq5', 'apq', 'dda', 'status']]\n",
    "\n",
    "# Generating the scatter plot using the scat_plt function\n",
    "scat_plt(shimer_vars['lShimer'],shimer_vars['dbShimer'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['lShimer'],shimer_vars['apq3'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['lShimer'],shimer_vars['apq5'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['lShimer'],shimer_vars['apq'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['lShimer'],shimer_vars['dda'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['dbShimer'],shimer_vars['apq3'],shimer_vars['status'] )\n",
    "scat_plt(shimer_vars['dbShimer'],shimer_vars['apq5'],shimer_vars['status'] )\n",
    "scat_plt(shimer_vars['dbShimer'],shimer_vars['apq'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['dbShimer'],shimer_vars['dda'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['apq3'],shimer_vars['apq5'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['apq3'],shimer_vars['apq'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['apq3'],shimer_vars['dda'],shimer_vars['status'] ) \n",
    "scat_plt(shimer_vars['apq5'],shimer_vars['apq'],shimer_vars['status'] )\n",
    "scat_plt(shimer_vars['apq5'],shimer_vars['dda'],shimer_vars['status'] )\n",
    "scat_plt(shimer_vars['apq'],shimer_vars['dda'],shimer_vars['status'] )\n",
    "\n",
    "# Eliminates the columns that are not important for the Shimmer\n",
    "cleaned_df_shimer = df.drop(columns=[\"minFF\", \"avFF\", \"maxFF\", \"percJitter\", \"absJitter\", \"rap\", \"ppq\", \"ddp\", \"apq\", \"apq5\"])\n",
    "\n",
    "########################################################################################################################################################\n",
    "\n",
    "# Combine the cleaned dataframes\n",
    "cleaned_df = pd.merge(cleaned_df_fundamental, cleaned_df_jitter, left_index=True, right_index=True).merge(cleaned_df_shimer, left_index=True, right_index=True)\n",
    "\n",
    "# Now 'cleaned_df' contains only the representative variables for each category, with this instruction we see the first lines\n",
    "cleaned_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38d201",
   "metadata": {},
   "source": [
    "### 3. Aggregating and transforming variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f75ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "gv = 'rap'\n",
    "df = cleaned_df.iloc[:, 1:]\n",
    "\n",
    "from group_and_average import group_and_average\n",
    "\n",
    "result = group_and_average(df, gv)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d095e42",
   "metadata": {},
   "source": [
    "### 4. Differentiating between controls (healthy subjects) and patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
